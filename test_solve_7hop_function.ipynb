{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d52bdd-2b85-4cae-9852-55d019df87a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# import stft_64_pad_0 as stft\n",
    "import stft_64 as stft\n",
    "from audio_processing import griffin_lim\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "import time\n",
    "import newton_method_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01ad0e6-c39f-4eff-abe0-bb7e14983e97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14])\n",
      "tensor([0.6561, 0.9268, 0.0702, 0.1676, 0.3579, 0.0400, 0.5828, 0.8942, 0.9843,\n",
      "        0.8540], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "hop_length = 2\n",
    "win_length = 4*hop_length\n",
    "channels = hop_length*2+1\n",
    "wav_length = hop_length*7\n",
    "\n",
    "audio_origin = torch.rand((1,wav_length), dtype=torch.float64)\n",
    "print(audio_origin.shape)\n",
    "print(audio_origin[0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596b5653-6b90-4e57-9226-0bcac9dcd36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stft_fn = stft.STFT(filter_length=4, hop_length=1, win_length=4,\n",
    "#                     window='hann')\n",
    "\n",
    "stft_fn = stft.STFT(filter_length=win_length, hop_length=hop_length, win_length=win_length,\n",
    "                    window=None)\n",
    "\n",
    "\n",
    "def compare(a,b):\n",
    "    return torch.mean(torch.abs(a-b)), torch.mean((a-b)*(a-b))\n",
    "\n",
    "def compare_L1(ori,gen):\n",
    "    return torch.mean(torch.abs(ori-gen)/torch.abs(ori))\n",
    "\n",
    "\n",
    "def compare_L2(a,b):\n",
    "    return torch.sum(torch.abs(a-b)), torch.sum((a-b)*(a-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b31542-c66e-496f-b85e-6be6f194bb72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 8])\n",
      "torch.Size([5])\n",
      "tensor([3.6956, 1.4934, 0.3733, 1.0496, 0.3617], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "magnitude, phase_origin = stft_fn.transform(audio_origin)\n",
    "\n",
    "forward_basis = stft_fn.forward_basis\n",
    "print(forward_basis.shape)\n",
    "start_frame = 0\n",
    "M_Rc = torch.sum(forward_basis[:channels,0,:] * audio_origin[:,start_frame: start_frame+win_length], dim =1)\n",
    "M_Ic = torch.sum(forward_basis[channels:,0,:] * audio_origin[:,start_frame: start_frame+win_length], dim =1)\n",
    "M_c_square = torch.sqrt(M_Rc**2+M_Ic**2)\n",
    "print(M_c_square.shape)\n",
    "print(magnitude[0,:10,start_frame+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1924da2-1682-493c-a375-771bf2d7eb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_guess = torch.rand((1, 7*hop_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98efef69-4693-400c-87d1-6e9a3fa79d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hop size 2\n",
      "Iter 19/20: Used times: 0.20\n",
      "\n",
      "ans    tensor([ 0.7494,  0.8226,  0.2020,  0.0589,  0.4304, -0.0018,  0.5331,  0.8622,\n",
      "         0.9449,  0.9341], dtype=torch.float64)\n",
      "origin tensor([0.6561, 0.9268, 0.0702, 0.1676, 0.3579, 0.0400, 0.5828, 0.8942, 0.9843,\n",
      "        0.8540], dtype=torch.float64)\n",
      "error        tensor([-0.0388,  0.0129,  0.0473, -0.0214,  0.0102, -0.0135, -0.0006,  0.0040,\n",
      "         0.0825, -0.0690], dtype=torch.float64)\n",
      "error origin tensor([ 0.0000e+00,  0.0000e+00,  8.8818e-16,  8.8818e-16,  0.0000e+00,\n",
      "         0.0000e+00, -2.2204e-16,  2.2204e-16,  0.0000e+00, -1.1102e-16],\n",
      "       dtype=torch.float64)\n",
      "ans part    3 tensor([0.5331, 0.8622], dtype=torch.float64)\n",
      "origin part 3 tensor([0.5828, 0.8942], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('hop size', hop_length)\n",
    "newton_method = newton_method_solver.hop_7_solver(forward_basis, hop_length, channels, win_length)\n",
    "ans = newton_method.solve(magnitude[:,:,2:6], initial_guess, n_iters=20)\n",
    "print('\\n')\n",
    "print('ans   ', ans[0, :10])\n",
    "print('origin', audio_origin[0, :10])\n",
    "print('error       ', newton_method.func(ans)[:10])\n",
    "print('error origin', newton_method.func(audio_origin)[:10])\n",
    "print('ans part    3', ans[0,3*hop_length:4*hop_length])\n",
    "print('origin part 3', audio_origin[0, 3*hop_length:4*hop_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3c9557-1bca-4db1-8258-0ca159c51c85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 9/10: Used times: 0.07ans    tensor([1.0189, 0.5585, 0.0404, 0.3709, 0.1276, 0.1135, 0.7939, 0.6844, 1.0652,\n",
      "        0.6971], dtype=torch.float64)\n",
      "origin tensor([0.6561, 0.9268, 0.0702, 0.1676, 0.3579, 0.0400, 0.5828, 0.8942, 0.9843,\n",
      "        0.8540], dtype=torch.float64)\n",
      "error        tensor([ 0.0126, -0.0578,  0.0024,  0.0428,  0.0797, -0.1043,  0.0879, -0.0630,\n",
      "         0.1210, -0.2754], dtype=torch.float64)\n",
      "error origin tensor([ 0.0000e+00,  0.0000e+00,  8.8818e-16,  8.8818e-16,  0.0000e+00,\n",
      "         0.0000e+00, -2.2204e-16,  2.2204e-16,  0.0000e+00, -1.1102e-16],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ans = newton_method.solve(magnitude[:,:,2:6], audio_origin + 0.1*torch.rand((1, 7*hop_length)), n_iters=10)\n",
    "print('ans   ', ans[0, :10])\n",
    "print('origin', audio_origin[0, :10])\n",
    "print('error       ', newton_method.func(ans)[:10])\n",
    "print('error origin', newton_method.func(audio_origin)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59fdd6a-5008-46ba-a2d1-8568b284ca9e",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab31256-566d-48be-bdfa-cc5817fec67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 33, 6161])\n"
     ]
    }
   ],
   "source": [
    "def load_wav_to_torch(full_path):\n",
    "    sampling_rate, data = read(full_path)\n",
    "    return torch.DoubleTensor(data.astype(np.float32)), sampling_rate\n",
    "\n",
    "audio_origin, sampling_rate = load_wav_to_torch('demo.wav')\n",
    "\n",
    "magnitude, phase_origin = stft_fn.transform(audio_origin.unsqueeze(0))\n",
    "print(magnitude.shape)\n",
    "# print(magnitude[0,:5,:2])\n",
    "# magnitude, phase_origin = stft_fn.transform(audio_origin.unsqueeze(0)*20)\n",
    "# print(magnitude.shape)\n",
    "# print(magnitude[0,:5,:2]/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd67f346-4b64-4b9b-ae19-86ffaf2aee81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/5:0.0596, 0.0110\n",
      "torch.Size([1, 33, 6161])\n",
      "torch.Size([1, 1, 98560])\n"
     ]
    }
   ],
   "source": [
    "def griffin_lim(magnitudes, stft_fn, n_iters=30):\n",
    "    \n",
    "    angles = np.angle(np.exp(2j * np.pi * np.random.rand(*magnitudes.size())))\n",
    "    angles = angles.astype(np.float64)\n",
    "    angles = torch.autograd.Variable(torch.from_numpy(angles))\n",
    "    signal = stft_fn.inverse(magnitudes, angles).squeeze(1)\n",
    "    # f=open('griffin lim.txt','a')\n",
    "    for i in range(n_iters):\n",
    "        if (i+1)%5==0:\n",
    "            # f.write('%d/%d:%.4f'%(i,n_iters,compare_L1(magnitude,MAG)))\n",
    "            a1,a2 = compare(signal, audio_origin)\n",
    "            print('%d/%d:%.4f, %.4f'%(i,n_iters,a1,a2))\n",
    "        MAG, angles = stft_fn.transform(signal)\n",
    "        signal = stft_fn.inverse(magnitudes, angles).squeeze(1)\n",
    "    return angles\n",
    "\n",
    "phase_griffin_lim =  griffin_lim(magnitude, stft_fn, n_iters=5)\n",
    "print(phase_griffin_lim.shape)\n",
    "audio_griffin_lim = stft_fn.inverse(magnitude, phase_griffin_lim)\n",
    "print(audio_griffin_lim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3d9e5d9-33eb-4250-b3ee-27679d23ab66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.7802e-05, -3.3379e-03, -4.2128e-03,  4.8132e-03,  4.7193e-03,\n",
      "        -2.9714e-03, -6.9590e-03,  4.2493e-03,  2.2001e-03, -3.5663e-03],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "START = 20\n",
    "\n",
    "ground_magnitude = magnitude[:,:,START+2:START+6]\n",
    "ground_audio_origin = audio_origin.unsqueeze(0)[:, START * hop_length : (START+7) * hop_length]\n",
    "initial_guess_audio = audio_griffin_lim.squeeze(0)[:, START * hop_length : (START+7) * hop_length]\n",
    "print(initial_guess_audio[0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bb8e669-62c0-43ea-b32a-9e8eef31d6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0206, dtype=torch.float64)\n",
      "tensor(48.5575, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(torch.abs(ground_magnitude)))\n",
    "normalize_coefficient = max(1/torch.mean(torch.abs(ground_magnitude)), 1)\n",
    "print(normalize_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9389be18-d29b-4881-b3c5-f7a5f24e35f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hop size 16\n",
      "Iter 4/5: Used times: 0.74\n",
      "\n",
      "ans    tensor([-0.0121,  0.0050,  0.0025,  0.0092, -0.0033, -0.0117,  0.0034,  0.0084,\n",
      "         0.0004, -0.0062], dtype=torch.float64)\n",
      "origin tensor([-0.0032, -0.0005,  0.0052,  0.0018, -0.0036, -0.0017,  0.0049, -0.0013,\n",
      "        -0.0011,  0.0027], dtype=torch.float64)\n",
      "error        tensor([ 5.6638e-04, -1.0644e-05,  8.0277e-04, -1.3585e-03,  2.2861e-03,\n",
      "        -1.3595e-03,  3.2977e-03,  1.0826e-03,  2.0253e-03,  1.7724e-03],\n",
      "       dtype=torch.float64)\n",
      "error origin tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4694e-18,\n",
      "         3.4694e-18,  2.1684e-18, -3.4694e-18, -3.4694e-18,  2.6021e-18],\n",
      "       dtype=torch.float64)\n",
      "ans    part 3 tensor([-0.0050,  0.0094,  0.0011, -0.0132,  0.0011,  0.0079, -0.0031, -0.0063,\n",
      "        -0.0017,  0.0048,  0.0039, -0.0059, -0.0086,  0.0060,  0.0142, -0.0096],\n",
      "       dtype=torch.float64)\n",
      "origin part 3 tensor([ 2.1603e-03,  6.6019e-03, -2.1932e-03, -5.6342e-03,  2.8682e-03,\n",
      "         4.9766e-03,  5.9078e-05, -6.6407e-03,  4.3462e-03,  4.8495e-03,\n",
      "        -5.8765e-03, -3.3446e-04,  8.3053e-04,  1.0014e-03,  1.8401e-03,\n",
      "        -1.7074e-03], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('hop size', hop_length)\n",
    "newton_method = newton_method_solver.hop_7_solver(forward_basis, hop_length, channels, win_length)\n",
    "ans = newton_method.solve(ground_magnitude*normalize_coefficient, initial_guess_audio*normalize_coefficient, n_iters=5)\n",
    "ans = ans/normalize_coefficient\n",
    "print('\\n')\n",
    "print('ans   ', ans[0, :10])\n",
    "print('origin', ground_audio_origin[0, :10])\n",
    "print('error       ', newton_method.test(ans, ground_magnitude)[:10])\n",
    "print('error origin', newton_method.test(ground_audio_origin, ground_magnitude)[:10])\n",
    "print('ans    part 3', ans[0,3*hop_length:4*hop_length])\n",
    "print('origin part 3', ground_audio_origin[0, 3*hop_length:4*hop_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8679d52c-29e3-4c6d-83ad-6906552ac0e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.4868e-03, -8.6788e-03,  6.4644e-03,  1.0670e-02, -1.6795e-02,\n",
      "         4.5687e-03, -1.0942e-03, -1.6698e-03, -6.8187e-03, -5.5373e-03,\n",
      "        -1.1018e-02, -6.4783e-03, -7.6258e-02, -1.6787e-02, -1.1233e-01,\n",
      "        -9.6085e-02, -1.2035e-01,  1.0264e-01,  1.3647e-02, -2.8443e-02,\n",
      "        -1.2698e-02,  2.0808e-02,  9.7335e-03,  2.6076e-02, -1.8474e-02,\n",
      "        -2.7175e-02, -2.9536e-03,  3.8386e-02, -4.7203e-02,  6.6492e-04,\n",
      "         3.2361e-05, -1.7807e-03, -1.5663e-03], dtype=torch.float64)\n",
      "tensor([ 0.0000, -0.0132, -0.0005, -0.0065,  0.0041,  0.0018,  0.0008, -0.0005,\n",
      "        -0.0121,  0.0057, -0.0001, -0.0266, -0.0168,  0.0419, -0.0183,  0.0122,\n",
      "        -0.0234, -0.0173,  0.0172, -0.0397, -0.0220, -0.0599, -0.0278, -0.0145,\n",
      "        -0.0381, -0.0086, -0.0117, -0.0300, -0.0017, -0.0090,  0.0046,  0.0037,\n",
      "         0.0000], dtype=torch.float64)\n",
      "tensor([ 0.0006,  0.0023,  0.0020,  0.0058,  0.0141,  0.0006, -0.0003,  0.0009,\n",
      "         0.0121,  0.0031, -0.0009,  0.0244,  0.0328,  0.0223,  0.0837,  0.0302,\n",
      "         0.0622,  0.0335,  0.0002,  0.0303,  0.0023,  0.0170,  0.0010,  0.0082,\n",
      "         0.0135,  0.0187,  0.0042,  0.0195,  0.0213,  0.0012,  0.0007,  0.0023,\n",
      "         0.0008], dtype=torch.float64)\n",
      "tensor([-0.0049,  0.0078, -0.0002, -0.0026,  0.0009, -0.0040,  0.0012,  0.0009,\n",
      "         0.0003, -0.0020, -0.0099,  0.0011, -0.0344,  0.0088, -0.0293, -0.0441,\n",
      "        -0.0156,  0.0385, -0.0089, -0.0038, -0.0219, -0.0266,  0.0258,  0.0070,\n",
      "        -0.0051, -0.0070,  0.0069,  0.0264, -0.0227,  0.0078,  0.0038,  0.0014,\n",
      "         0.0008], dtype=torch.float64)\n",
      "tensor([ 0.0000e+00,  1.1080e-02, -4.4565e-03, -6.1098e-03, -3.0358e-03,\n",
      "        -1.5149e-03, -1.1804e-03, -1.8737e-05,  1.8024e-03, -4.4806e-03,\n",
      "        -6.6720e-03,  2.7769e-03, -2.9460e-02,  2.1020e-02,  7.0692e-03,\n",
      "        -5.0043e-02, -5.8400e-02,  5.9155e-02,  1.9833e-02,  1.8146e-02,\n",
      "         7.0886e-03,  3.8068e-02, -1.2239e-02, -2.0484e-02, -2.8439e-02,\n",
      "        -6.8741e-03,  3.8942e-03,  1.2638e-02,  1.2575e-02,  6.5042e-04,\n",
      "         1.1266e-03,  1.1301e-03,  0.0000e+00], dtype=torch.float64)\n",
      "tensor([ 0.0000e+00, -3.4694e-18, -3.4694e-18,  3.4694e-18,  2.1684e-18,\n",
      "         8.6736e-19,  2.1684e-19, -4.3368e-19,  1.7347e-18,  2.6021e-18,\n",
      "         1.7347e-18, -4.3368e-19,  1.3878e-17,  0.0000e+00,  0.0000e+00,\n",
      "         1.3878e-17,  0.0000e+00, -2.7756e-17,  6.9389e-18,  6.9389e-18,\n",
      "         3.4694e-18, -2.7756e-17, -1.0408e-17,  0.0000e+00, -1.0408e-17,\n",
      "         3.4694e-18, -1.7347e-18,  0.0000e+00,  3.4694e-18,  3.4694e-18,\n",
      "         8.6736e-19,  2.3852e-18,  0.0000e+00], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "hop_iter =0\n",
    "start_frame = hop_iter * hop_length\n",
    "M_Rc = torch.sum(forward_basis[:channels,0,:] * ans[:,start_frame: start_frame + win_length], dim =1)\n",
    "M_Ic = torch.sum(forward_basis[channels:,0,:] * ans[:,start_frame: start_frame + win_length], dim =1)\n",
    "M_c_square = torch.sqrt(M_Rc**2+M_Ic**2) - (ground_magnitude)[0,:,hop_iter]\n",
    "print(M_Rc)\n",
    "print(M_Ic)\n",
    "print(M_c_square)\n",
    "M_Rc = torch.sum(forward_basis[:channels,0,:] * ground_audio_origin[:,start_frame: start_frame + win_length], dim =1)\n",
    "M_Ic = torch.sum(forward_basis[channels:,0,:] * ground_audio_origin[:,start_frame: start_frame + win_length], dim =1)\n",
    "M_c_square = torch.sqrt(M_Rc**2+M_Ic**2) - (ground_magnitude)[0,:,hop_iter]\n",
    "print(M_Rc)\n",
    "print(M_Ic)\n",
    "print(M_c_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdaa4431-268a-4f4c-a451-5e36b2f0b5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 33, 6161])\n",
      "hop size 16\n",
      "Iter 4/5: Used times: 0.89\n",
      "\n",
      "ans    tensor([-0.0032, -0.0005,  0.0053,  0.0019, -0.0037, -0.0019,  0.0048, -0.0013,\n",
      "        -0.0010,  0.0029], dtype=torch.float64)\n",
      "origin tensor([-0.0032, -0.0005,  0.0052,  0.0018, -0.0036, -0.0017,  0.0049, -0.0013,\n",
      "        -0.0011,  0.0027], dtype=torch.float64)\n",
      "error        tensor([-2.7767e-05,  5.4979e-05,  2.2266e-05,  4.9457e-06,  1.9039e-05,\n",
      "        -1.6362e-05,  6.2120e-06, -5.8554e-06, -2.4094e-05,  3.2937e-05],\n",
      "       dtype=torch.float64)\n",
      "error origin tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4694e-18,\n",
      "         3.4694e-18,  2.1684e-18, -3.4694e-18, -3.4694e-18,  2.6021e-18],\n",
      "       dtype=torch.float64)\n",
      "ans    part 3 tensor([ 2.1559e-03,  6.6631e-03, -1.9603e-03, -5.4287e-03,  2.9059e-03,\n",
      "         4.9139e-03, -5.2472e-05, -6.8190e-03,  4.2392e-03,  4.9341e-03,\n",
      "        -5.8091e-03, -2.7459e-04,  9.5751e-04,  1.0057e-03,  1.7753e-03,\n",
      "        -1.7715e-03], dtype=torch.float64)\n",
      "origin part 3 tensor([ 2.1603e-03,  6.6019e-03, -2.1932e-03, -5.6342e-03,  2.8682e-03,\n",
      "         4.9766e-03,  5.9078e-05, -6.6407e-03,  4.3462e-03,  4.8495e-03,\n",
      "        -5.8765e-03, -3.3446e-04,  8.3053e-04,  1.0014e-03,  1.8401e-03,\n",
      "        -1.7074e-03], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def load_wav_to_torch(full_path):\n",
    "    sampling_rate, data = read(full_path)\n",
    "    return torch.DoubleTensor(data.astype(np.float32)), sampling_rate\n",
    "\n",
    "audio_origin, sampling_rate = load_wav_to_torch('demo.wav')\n",
    "\n",
    "magnitude, phase_origin = stft_fn.transform(audio_origin.unsqueeze(0))\n",
    "print(magnitude.shape)\n",
    "\n",
    "start_frame = 20\n",
    "\n",
    "ground_magnitude = magnitude[:,:,start_frame+2:start_frame+6]\n",
    "ground_audio_origin = audio_origin.unsqueeze(0)[:, start_frame * hop_length : (start_frame+7) * hop_length]\n",
    "initial_guess_audio = ground_audio_origin + ground_audio_origin*torch.rand((1,7*hop_length))\n",
    "\n",
    "print('hop size', hop_length)\n",
    "newton_method = newton_method_solver.hop_7_solver(forward_basis, hop_length, channels, win_length)\n",
    "ans = newton_method.solve(ground_magnitude, initial_guess_audio, n_iters=5)\n",
    "print('\\n')\n",
    "print('ans   ', ans[0, :10])\n",
    "print('origin', ground_audio_origin[0, :10])\n",
    "print('error       ', newton_method.test(ans, ground_magnitude)[:10])\n",
    "print('error origin', newton_method.test(ground_audio_origin, ground_magnitude)[:10])\n",
    "print('ans    part 3', ans[0,3*hop_length:4*hop_length])\n",
    "print('origin part 3', ground_audio_origin[0, 3*hop_length:4*hop_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80d13159-2bdd-4bbc-98b3-d3e54eed3827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4142, 0.7071], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "guess = torch.tensor([2,1], dtype=torch.float64, requires_grad = True) \n",
    "\n",
    "# function to optimize\n",
    "def my_func(x):\n",
    "    ans = torch.zeros((3), dtype=torch.float64)\n",
    "    ans[0] = x[0] - 2*x[1]\n",
    "    ans[1] = x[0]*x[1]-1\n",
    "    ans[2] = x[0]+x[1]- np.sqrt(2)*1.5\n",
    "    return ans\n",
    "\n",
    "def newton(func, guess, runs=5): \n",
    "    for _ in range(runs): \n",
    "        # evaluate our function with current value of `guess`\n",
    "        J = torch.autograd.functional.jacobian(my_func, guess)\n",
    "            # print('J shape', J.shape)\n",
    "           \n",
    "        J = J.squeeze(1)\n",
    "        # print(J)\n",
    "            \n",
    "        Q, R = np.linalg.qr(J, mode='reduced')\n",
    "        # print(Q, R)\n",
    "        Qb = np.matmul(Q.T, my_func(guess).detach().numpy())\n",
    "        minus = np.linalg.solve(R,Qb)\n",
    "        \n",
    "        # Q, R = np.linalg.qr(J, mode='reduced')\n",
    "        # # print(Q, R)\n",
    "        # Qb = np.matmul(Q.T, [value[0].detach().numpy(), value[1].detach().numpy()])\n",
    "        # minus = np.linalg.solve(R,Qb)\n",
    "        # update our `guess` based on the gradient\n",
    "        guess.data -= minus\n",
    "        # zero out current gradient to hold new gradients in next iteration \n",
    "        \n",
    "    return guess.data # return our final `guess` after 5 updates\n",
    "\n",
    "# call starts\n",
    "result = newton(my_func, guess)\n",
    "\n",
    "# output of `result`\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78431cf-0831-4540-8fa3-bc4ad2017a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
